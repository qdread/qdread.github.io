{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a TSV of publications with metadata and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). The core python code is also in `publications.py`. Run either from the `markdown_generator` folder after replacing `publications.tsv` with one containing your data.\n",
    "\n",
    "TODO: Make this work with BibTex and other databases of citations, rather than Stuart's non-standard TSV format and citation style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "\n",
    "The TSV needs to have the following columns: pub_date, title, venue, excerpt, citation, site_url, and paper_url, with a header at the top. \n",
    "\n",
    "- `excerpt` and `paper_url` can be blank, but the others must have values. \n",
    "- `pub_date` must be formatted as YYYY-MM-DD.\n",
    "- `url_slug` will be the descriptive part of the .md file and the permalink URL for the page about the paper. The .md file will be `YYYY-MM-DD-[url_slug].md` and the permalink will be `https://[yourdomain]/publications/YYYY-MM-DD-[url_slug]`\n",
    "\n",
    "This is how the raw file looks (it doesn't look pretty, use a spreadsheet or other program to edit and create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub_date\ttitle\tvenue\texcerpt\tcitation\turl_slug\tpaper_url\n",
      "2019-02-27\tTowards connecting biodiversity and geodiversity across scales with satellite remote sensing\tGlobal Ecology and Biogeography\t\t\"Zarnetske, P. L., Q. D. Read, S. Record, K. Gaddis, S. Pau, M. Hobi, S. L. Malone, J. K. Costanza, K. M. Dahlin, A. Latimer, A. M. Wilson, J. M. Grady, S. Ollinger, A. O. Finley. 2019. Towards connecting biodiversity and geodiversity across scales with satellite remote sensing. Global Ecology and Biogeography. DOI: 10.1111/geb.12887.\"\tzarnetske-et-al-2019\thttps://onlinelibrary.wiley.com/doi/full/10.1111/geb.12887\n",
      "2019-03-12\tFungal colonization of plant roots is resistant to nitrogen addition and resilient to dominant species losses\tEcosphere\tOpen access!\t\"Henning, J. A., Q. D. Read, N. J. Sanders, and A. T. Classen. 2019. Fungal colonization of plant roots is resistant to nitrogen addition and resilient to dominant species losses. Ecosphere. DOI: 10.1002/ecs2.2640.\"\thenning-et-al-2019\thttps://esajournals.onlinelibrary.wiley.com/doi/full/10.1002/ecs2.2640\n",
      "2018-10-20\t\"Size, niches, and the latitudinal diversity gradient\"\tTeaching Issues and Experiments in Ecology\tOpen access!\t\"Grady, J. M., Q. D. Read, S. Record, P. L. Zarnetske., B. Baiser, K. Thorne, and J. Belmaker. 2018. Size, niches, and the latitudinal diversity gradient. Teaching Issues and Experiments in Ecology, Vol. 14, Figure Set 1.\"\tgrady-et-al-2018\thttp://tiee.esa.org/vol/v14/issues/figure_sets/grady/abstract.html\n",
      "2018-10-01\tAmong-species overlap in rodent body size distributions predicts species richness along a temperature gradient\tEcography\t\t\"Read, Q. D., J. M. Grady, P. L. Zarnetske, S. Record, B. Baiser, J. Belmaker, M.-N. Tuanmu, A. Strecker, L. Beaudrot, and K. M. Thibault. 2018. Among-species overlap in rodent body size distributions predicts species richness along a temperature gradient. Ecography. DOI: 10.1111/ecog.03641\"\tread-et-al-2018-ecography\thttps://onlinelibrary.wiley.com/doi/10.1111/ecog.03641\n",
      "2018-01-24\tTropical bird species have less variable body sizes\tBiology Letters\t\t\"Read, Q. D., B. Baiser, J. M. Grady, P. L. Zarnetske, S. Record, and J. Belmaker. 2018. Tropical bird species have less variable body sizes. Biology Letters 20170453. DOI: 10.1098/rsbl.2017.0453\"\tread-et-al-2018-biology-letters\thttps://royalsocietypublishing.org/doi/full/10.1098/rsbl.2017.0453\n",
      "2018-03-06\tAboveground resilience to species loss but belowground resistance to nitrogen addition in a montane plant community\tJournal of Plant Ecology\t\t\"Read, Q. D., J. A. Henning, A. T. Classen, and N. J. Sanders. 2017. Aboveground resilience to species loss but belowground resistance to nitrogen addition in montane plant communities. Journal of Plant Ecology. DOI: 10.1093/jpe/rtx015\"\tread-et-al-2018-j-plant-ecology\thttps://academic.oup.com/jpe/article/11/3/351/3051921\n",
      "2018-05-01\tShort-term responses to warming vary between native vs. exotic species and with latitude in an early successional plant community\tOecologia\t\t\"Welshofer, K. B., P. L. Zarnetske, N. K. Lany, and Q. D. Read. 2018. Short-term responses to warming vary between native vs. exotic species and with latitude in an early successional plant community. Oecologia. DOI: h10.1007/s00442-018-4111-9\"\twelshofer-et-al-2018\thttps://link.springer.com/article/10.1007/s00442-018-4111-9\n",
      "2017-09-01\tIntraspecific variation in traits reduces ability of trait-based models to predict community structure\tJournal of Vegetation Science\t\t\"Read, Q. D., J. A. Henning, and N. J. Sanders. 2017. Intraspecific variation in traits reduces ability of trait-based models to predict community structure. Journal of Vegetation Science. DOI: 10.1111/jvs.12555\"\tread-et-al-2017-j-veg-sci\thttps://onlinelibrary.wiley.com/doi/full/10.1111/jvs.12555\n",
      "2017-07-01\tConsistently inconsistent drivers of patterns of microbial diversity and abundance at macroecological scales\tEcology\tOpen access! First author is an undergraduate that I helped mentor.\t\"Hendershot, J. N.*, Q. D. Read, J. A. Henning, N. J. Sanders, and A. T. Classen. 2017. Consistently inconsistent drivers of patterns of microbial diversity and abundance at macroecological scales. Ecology. DOI: 10.1002/ecy.1829\"\thendershot-et-al-2017\thttps://esajournals.onlinelibrary.wiley.com/doi/full/10.1002/ecy.1829\n",
      "2017-12-19\tMapping local and global variability in plant trait distributions\tPNAS\t\t\"Butler, E. E., A. Datta, …, Q. D. Read, …, and P. B. Reich. 2017. Mapping local and global variability in plant trait distributions. Proceedings of the National Academy of Sciences. DOI:10.1073/pnas.1708984114 \"\tbutler-et-al-2017\thttps://www.pnas.org/content/114/51/E10937\n",
      "2016-07-01\tAccounting for the nested nature of genetic variation across levels of organization improves our understanding of biodiversity and community ecology\tOikos\tAwarded Editor's Choice.\t\"Read, Q. D., S. M. Hoban, M. B. Eppinga, J. A. Schweitzer, and J. K. Bailey. 2016. Accounting for the nested nature of genetic variation across levels of organization improves our understanding of biodiversity and community ecology. Oikos 125:895-904. DOI:  10.1111/oik.02760\"\tread-et-al-2016-oikos\thttps://onlinelibrary.wiley.com/doi/full/10.1111/oik.02760\n",
      "2016-07-01\tPlant-soil feedbacks: connecting ecosystem ecology and evolution\tFunctional Ecology\t\t\"Van Nuland, M. E., R. C. Wooliver, A. A. Pfennigwerth, Q. D. Read, I. M. Ware, L. Mueller, J. A. Fordyce, J. A. Schweitzer, and J. K. Bailey. 2016. Plant-soil feedbacks: connecting ecosystem ecology and evolution. Functional Ecology. DOI: 10.1111/1365-2435.12690\"\tvannuland-et-al-2016\thttps://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/1365-2435.12690\n",
      "2016-08-01\tConsequences of exotic host use: impacts on Lepidoptera and a test of the ecological trap hypothesis\tOecologia\tFirst author is an undergraduate that I helped mentor. Highlighted Student Research.\t\"Yoon, S. A.* and Q. D. Read. 2016. Consequences of exotic host use: impacts on Lepidoptera and a test of the ecological trap hypothesis. Oecologia. DOI: 10.1007/s00442-016-3560-2\"\tyoon-and-read-2016\thttps://link.springer.com/article/10.1007/s00442-016-3560-2\n",
      "2015-09-01\tPreparing biology graduate teaching assistants for their roles as instructors: an assessment of institutional approaches\tCBE-Life Sciences Education\tOpen access!\t\"Schussler, E. E., Q. D. Read, G. Marbach-Ad, K. Miller, and M. Ferzli. 2015. Preparing biology graduate teaching assistants for their roles as instructors: an assessment of institutional approaches. CBE-Life Sciences Education 14:1-11. DOI: 10.1187/cbe.14-11-0196\"\tschussler-et-al-2015\thttps://www.lifescied.org/doi/10.1187/cbe.14-11-0196\n",
      "2014-02-01\tConvergent effects of elevation on functional leaf traits within and among species\tFunctional Ecology\tNominated for the British Ecological Society's Haldane Prize for Young Investigators\t\"Read, Q. D., L. C. Moorhead, N. G. Swenson, J. K. Bailey, and N. J. Sanders. 2014. Convergent effects of elevation on functional leaf traits within and among species. Functional Ecology 28:37-45. DOI: 10.1111/1365-2435.12162\"\tread-et-al-2014-functional-ecology\thttps://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/1365-2435.12162\n",
      "2013-12-07\tSpecies identity influences belowground arthropod assemblages via functional traits\tAnnals of Botany Plants\tOpen access! Awarded Editor's Choice.\t\"Gorman, C. E., Q. D. Read, M. E. Van Nuland, and others. 2013. Phylogenetic similarity aboveground leads to community similarity belowground through conservatism of functional traits. Annals of Botany Plants plt049. DOI: 10.1093/aobpla/plt049\"\tgorman-et-al-2013\thttps://academic.oup.com/aobpla/article/doi/10.1093/aobpla/plt049/163635\n",
      "2013-11-12\tFire promotes pollinator visitation: implications for ameliorating declines of pollination services\tPLoS One\tOpen access!\t\"Van Nuland, M. E., E. N. Haag, J. A. Bryant, Q. D. Read, and others. 2013. Fire promotes pollinator visitation: implications for ameliorating declines of pollination services. PLoS One 8:e79853. DOI: 10.1371/journal.pone.0079853\"\tvannuland-et-al-2013\thttps://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079853\n",
      "2012-02-29\tEvidence from individual inference for high-dimensional coexistence: long term experiments on recruitment response\tPLoS One\tOpen access!\t\"Clark, J. S., A. S. Powell, B. D. Soltoff, and Q. D. Read. 2012. Evidence from individual inference for high-dimensional coexistence: long term experiments on recruitment response. PLoS One 7:e30050. DOI: 10.1371/journal.pone.0030050\"\tclark-et-al-2012\thttps://journals.plos.org/plosone/article?id=10.1371/journal.pone.0030050\n"
     ]
    }
   ],
   "source": [
    "!cat publications.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pandas\n",
    "\n",
    "We are using the very handy pandas library for dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import TSV\n",
    "\n",
    "Pandas makes this easy with the read_csv function. We are using a TSV, so we specify the separator as a tab, or `\\t`.\n",
    "\n",
    "I found it important to put this data in a tab-separated values format, because there are a lot of commas in this kind of data and comma-separated values can get messed up. However, you can modify the import statement, as pandas also has read_excel(), read_json(), and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x85 in position 25: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x85 in position 25: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e87d07abf925>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpublications\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"publications.tsv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpublications\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1034\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x85 in position 25: invalid start byte"
     ]
    }
   ],
   "source": [
    "publications = pd.read_csv(\"publications.tsv\", sep=\"\\t\", header=0)\n",
    "publications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escape special characters\n",
    "\n",
    "YAML is very picky about how it takes a valid string, so we are replacing single and double quotes (and ampersands) with their HTML encoded equivilents. This makes them look not so readable in raw format, but they are parsed and rendered nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the markdown files\n",
    "\n",
    "This is where the heavy lifting is done. This loops through all the rows in the TSV dataframe, then starts to concatentate a big string (```md```) that contains the markdown for each type. It does the YAML metadata first, then does the description for the individual page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for row, item in publications.iterrows():\n",
    "    \n",
    "    md_filename = str(item.pub_date) + \"-\" + item.url_slug + \".md\"\n",
    "    html_filename = str(item.pub_date) + \"-\" + item.url_slug\n",
    "    year = str(item.pub_date)[:4]\n",
    "    \n",
    "    ## YAML variables\n",
    "    \n",
    "    md = \"---\\ntitle: \\\"\"   + item.title + '\"\\n'\n",
    "    \n",
    "    md += \"\"\"collection: publications\"\"\"\n",
    "    \n",
    "    md += \"\"\"\\npermalink: /publication/\"\"\" + html_filename\n",
    "    \n",
    "    if len(str(item.excerpt)) > 5:\n",
    "        md += \"\\nexcerpt: '\" + html_escape(item.excerpt) + \"'\"\n",
    "    \n",
    "    md += \"\\ndate: \" + str(item.pub_date) \n",
    "    \n",
    "    md += \"\\nvenue: '\" + html_escape(item.venue) + \"'\"\n",
    "    \n",
    "    if len(str(item.paper_url)) > 5:\n",
    "        md += \"\\npaperurl: '\" + item.paper_url + \"'\"\n",
    "    \n",
    "    md += \"\\ncitation: '\" + html_escape(item.citation) + \"'\"\n",
    "    \n",
    "    md += \"\\n---\"\n",
    "    \n",
    "    ## Markdown description for individual page\n",
    "        \n",
    "    if len(str(item.excerpt)) > 5:\n",
    "        md += \"\\n\" + html_escape(item.excerpt) + \"\\n\"\n",
    "    \n",
    "    if len(str(item.paper_url)) > 5:\n",
    "        md += \"\\n[Download paper here](\" + item.paper_url + \")\\n\" \n",
    "        \n",
    "    md += \"\\nRecommended citation: \" + item.citation\n",
    "    \n",
    "    md_filename = os.path.basename(md_filename)\n",
    "       \n",
    "    with open(\"../_publications/\" + md_filename, 'w') as f:\n",
    "        f.write(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files are in the publications directory, one directory below where we're working from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-10-01-paper-title-number-1.md\n",
      "2010-10-01-paper-title-number-2.md\n",
      "2012-soltoff-et-al-2012.md\n",
      "2013-gorman-et-al-2013.md\n",
      "2013-vannuland-et-al-2013.md\n",
      "2014-read-et-al-2014-functional-ecology.md\n",
      "2015-10-01-paper-title-number-3.md\n",
      "2015-schussler-et-al-2015.md\n",
      "2016-read-et-al-2016-oikos.md\n",
      "2016-vannuland-et-al-2016.md\n",
      "2016-yoon-and-read-2016.md\n",
      "2017-butler-et-al-2017.md\n",
      "2017-hendershot-et-al-2017.md\n",
      "2017-read-et-al-2017-j-veg-sci.md\n",
      "2018-grady-et-al-2018.md\n",
      "2018-read-et-al-2018-biology-letters.md\n",
      "2018-read-et-al-2018-ecography.md\n",
      "2018-read-et-al-2018-j-plant-ecology.md\n",
      "2018-welshofer-et-al-2018.md\n",
      "2019-henning-et-al-2019.md\n",
      "2019-zarnetske-et-al-2019.md\n"
     ]
    }
   ],
   "source": [
    "!ls ../_publications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\r\n",
      "title: \"Paper Title Number 1\"\r\n",
      "collection: publications\r\n",
      "permalink: /publication/2009-10-01-paper-title-number-1\r\n",
      "excerpt: 'This paper is about the number 1. The number 2 is left for future work.'\r\n",
      "date: 2009-10-01\r\n",
      "venue: 'Journal 1'\r\n",
      "paperurl: 'http://academicpages.github.io/files/paper1.pdf'\r\n",
      "citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'\r\n",
      "---\r\n",
      "This paper is about the number 1. The number 2 is left for future work.\r\n",
      "\r\n",
      "[Download paper here](http://academicpages.github.io/files/paper1.pdf)\r\n",
      "\r\n",
      "Recommended citation: Your Name, You. (2009). \"Paper Title Number 1.\" <i>Journal 1</i>. 1(1)."
     ]
    }
   ],
   "source": [
    "!cat ../_publications/2009-10-01-paper-title-number-1.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
